{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "SBERT_MODEL = \"all-MiniLM-L6-v2\"\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw_dataset = load_dataset(\"jjmachan/NSFW-questions\",split=\"train\")\n",
    "pro_social_dataset = load_dataset(\"allenai/prosocial-dialog\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_rot_safetylabels(dataset):\n",
    "    rots = [item[\"rots\"] for item in dataset]\n",
    "    safety_annotations = [item[\"safety_label\"] for item in dataset]\n",
    "    results = {}\n",
    "    for rots, sfty in zip(rots, safety_annotations):\n",
    "        for rot in rots:\n",
    "            if rot not in results.keys():\n",
    "                results[rot] = sfty\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8195b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_sfty = match_rot_safetylabels(pro_social_dataset)\n",
    "all_rots = list(set(rot_sfty.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b3e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorizer(model=SBERT_MODEL):\n",
    "    return SentenceTransformer(model)\n",
    "\n",
    "\n",
    "def vectorize_text(model, texts):\n",
    "    return model.encode(texts, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_vectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_vector = vectorize_text(model,all_rots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as sp\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "THRESHOLD = 0.65\n",
    "\n",
    "\n",
    "def match_query_rot(q,m):\n",
    "   \n",
    "    cosine_sim = 1 - sp.distance.cdist(q, m, \"cosine\")\n",
    "    sim_indices = np.argwhere(cosine_sim >= THRESHOLD)\n",
    "    return sim_indices\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "def match_rot_post(dataset):\n",
    "    \n",
    "    dic = {}\n",
    "    posts = [item[\"title\"] for item in dataset]\n",
    "    post_vector = vectorize_text(model,posts)\n",
    "    for idx in tqdm(range(0,len(post_vector),BATCH_SIZE)):\n",
    "        sim_indices = match_query_rot(post_vector[idx:idx+BATCH_SIZE],rot_vector)\n",
    "        for post_idx,rot_idx in sim_indices:\n",
    "            rot = all_rots[rot_idx]\n",
    "            dic.update({dataset[int(post_idx)+idx]['post_id']:{\"rots\":[rot],\n",
    "                                             \"safety_label\":rot_sfty.get(rot)}})\n",
    "    return dic\n",
    "           \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5169d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Turaround perc\",len(result_dict)/len(nsfw_dataset) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(example):\n",
    "    stopwords = [\"Ladies\",\"Women\",\"Gals\",\"Men\",\"guys\"]\n",
    "    regex = \"\".join([f'{word}(,)?|' for word in stopwords])\n",
    "    example['title'] = re.sub(regex,'',example['title'],flags=re.IGNORECASE)            \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rot_label(example):\n",
    "    \n",
    "    post_id = example['post_id']\n",
    "    if post_id in result_dict.keys():\n",
    "        example[\"rots\"] = result_dict.get(post_id)['rots']\n",
    "        example['safety_label'] = result_dict.get(post_id)['safety_label']\n",
    "        \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_response(example):\n",
    "    \n",
    "    comments = [example[key] for key in [\"C1\",\"C2\"] if example[key] is not None]\n",
    "    comments = [comment for comment in comments if (len(sent_tokenize(comment))>1) and (len(sent_tokenize(comment))<3) ]\n",
    "    print(comments)\n",
    "    if comments:\n",
    "        example[\"response\"] = np.random.choice(comments,1)[0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return example\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba914ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = [[]] * len(nsfw_dataset)\n",
    "nsfw_dataset = nsfw_dataset.add_column(\"rots\", new_column)\n",
    "new_column = [None] * len(nsfw_dataset)\n",
    "nsfw_dataset = nsfw_dataset.add_column(\"safety_label\", new_column)\n",
    "nsfw_dataset = nsfw_dataset.add_column(\"response\", new_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw_dataset = nsfw_dataset.map(filter_stopwords)\n",
    "nsfw_dataset = nsfw_dataset.map(add_rot_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAssistant",
   "language": "python",
   "name": "openassistant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
